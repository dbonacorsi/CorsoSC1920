{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 2","language":"python","name":"python2"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.16"},"colab":{"name":"Project_IRIS2_Keras.ipynb","provenance":[{"file_id":"https://github.com/bonacor/CorsoSwComp/blob/master/Project_IRIS2_Keras_SOLUTION.ipynb","timestamp":1589297441845}],"collapsed_sections":["AUiOhyHngVSn","m3-TjUKfgVSp","ju6S9p1ogVT_","IeiKotQPgVUA","BmKMZB3R3Ucx","Xqb7L9Sd3UAI","kOjMTLpcgVWM","aojQqRbG66r1","YSj9kLXogVWZ","_rUgHNR19ndY","B4S8oaIfAvTD"]}},"cells":[{"cell_type":"markdown","metadata":{"id":"_tQonx1ugVSl","colab_type":"text"},"source":["# Project IRIS - Phase 2: Keras</font>"]},{"cell_type":"markdown","metadata":{"id":"7fHGSw3ngVSn","colab_type":"text"},"source":["In this tutorial you will discover **how to use Keras+sklearn to develop and evaluate a NN model for a multiclass classification problem**. \n","\n","Goals:\n","* How to load data from CSV and make it available to Keras\n","* How to prepare multiclass classification data for modeling with NNs\n","* How to evaluate Keras NN models with scikit-learn"]},{"cell_type":"markdown","metadata":{"id":"AUiOhyHngVSn","colab_type":"text"},"source":["# <font color='blue'>A. Description of the input data"]},{"cell_type":"markdown","metadata":{"id":"TJO0x0PBgVSo","colab_type":"text"},"source":["Same as previous notebook."]},{"cell_type":"markdown","metadata":{"id":"m3-TjUKfgVSp","colab_type":"text"},"source":["# <font color='blue'>B. Set-up and data import"]},{"cell_type":"markdown","metadata":{"id":"3kGqs9AdgVSq","colab_type":"text"},"source":["Start by importing all classes and functions you will need:\n","\n","* data loading functionalities from **Pandas** (learn more [here](https://pandas.pydata.org/)) - same as before\n","* data preparation and model evaluation from **Scikit-learn** - referred to as `sklearn` in the following (learn more [here](https://scikit-learn.org/stable/)) - same as before\n","* all the functionality we require from **Keras** (learn more [here](https://keras.io/))\n","* more as needed, e.g. **numpy**, **matplotlib**, .. (learn more [here](https://numpy.org/) and [here](https://matplotlib.org/) respectively)\n"]},{"cell_type":"code","metadata":{"id":"4TXY6HuVgVSr","colab_type":"code","colab":{}},"source":["# pandas\n","from pandas import read_csv\n","\n","# sklearn\n","from sklearn.preprocessing import LabelEncoder\n","#from sklearn.pipeline import Pipeline\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import cross_val_score\n","from sklearn.model_selection import KFold\n","\n","# keras\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.wrappers.scikit_learn import KerasClassifier\n","from keras.utils import np_utils\n","\n","# numpy\n","import numpy as np\n","\n","# matplotlib\n","import matplotlib.pyplot as plt\n","%matplotlib inline"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z2umkG4KgVSx","colab_type":"code","colab":{}},"source":["# fix random seed for reproducibility\n","seed = 123\n","np.random.seed(seed)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XWy3h-e_gVS0","colab_type":"text"},"source":["Download the data."]},{"cell_type":"code","metadata":{"id":"zwUZfhkNgVS5","colab_type":"code","colab":{}},"source":["#today, get it from here for example:\n","#!wget https://raw.githubusercontent.com/bonacor/CorsoSwComp/master/iris.data.csv\n","#!ls -trl iris.data.csv\n","#!head -5 iris.data.csv\n","\n","import pandas as pd\n","\n","url = 'https://raw.githubusercontent.com/dbonacorsi/SC_AA1920/master/datasets/iris.data.csv'\n","\n","names = ['sepal-l', 'sepal-w', 'petal-l', 'petal-w', 'class']\n","dataset = pd.read_csv(url, names=names)\n","dataset"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sSRg84ZE1H4v","colab_type":"text"},"source":["Import the data and prepare it."]},{"cell_type":"code","metadata":{"id":"fllLc6M8gVTm","colab_type":"code","colab":{}},"source":["# load dataset\n","#dataframe = read_csv(\"iris.data.csv\", header=None)\n","data = dataset.values\n","X = data[:,0:4].astype(float)   # columns from 1st to 4th into X\n","Y = data[:,4]                   # column 5th into Y"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"Pqimv2jDgVTw","colab_type":"code","colab":{}},"source":["len(X)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6Ndbd-ghgVT0","colab_type":"code","colab":{}},"source":["len(Y)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VQV433-vgVT4","colab_type":"code","colab":{}},"source":["X"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BxlmyDtugVT8","colab_type":"code","colab":{}},"source":["Y"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ju6S9p1ogVT_","colab_type":"text"},"source":["# <font color='blue'>C. Data preparation/preprocessing"]},{"cell_type":"markdown","metadata":{"id":"MkvBMKw8AgF_","colab_type":"text"},"source":["We did some data exploration in the previous notebook. Here, we focus a bit more on data preprocessing.\n","\n","> *(NOTE: different datasets may require different data manipulation/preprocessing. This just applies to this specific case)*\n","\n"]},{"cell_type":"markdown","metadata":{"id":"IeiKotQPgVUA","colab_type":"text"},"source":["## C1. One-hot encoding the output variable"]},{"cell_type":"markdown","metadata":{"id":"DX6s6Nqq2Or8","colab_type":"text"},"source":["I need to go from\n","\n","    Iris-setosa\n","    Iris-versicolor\n","    Iris-virginica\n","    \n","to\n","\n","    1, 0, 0\n","    0, 1, 0\n","    0, 0, 1\n","    \n","I will do it in 2 subsequent steps:\n","   1. encoding the strings consistently to integers \n","   2. convert the vector of integers to a one-hot encoding \n"]},{"cell_type":"code","metadata":{"id":"-Obni1x2gVUB","colab_type":"code","colab":{}},"source":["# step 1: encode class values as integers\n","encoder = LabelEncoder()\n","encoder.fit(Y)\n","encoded_Y = encoder.transform(Y)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"66A9-zcVgVUE","colab_type":"text"},"source":["Check:"]},{"cell_type":"code","metadata":{"id":"jv2_H2dtgVUF","colab_type":"code","colab":{}},"source":["encoder"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oEqkyJtBgVUk","colab_type":"code","colab":{}},"source":["encoded_Y"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"T9sVwLQpgVWA","colab_type":"code","colab":{}},"source":["# step 2: do one-hot encoding\n","transformed_Y = np_utils.to_categorical(encoded_Y)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hKYbjlh1gVWF","colab_type":"code","colab":{}},"source":["transformed_Y"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BmKMZB3R3Ucx","colab_type":"text"},"source":["### <font color='red'>Exercise 1: `fit` or `fit and transform` (in sklearn)?"]},{"cell_type":"markdown","metadata":{"id":"tuoIvEuH3UWt","colab_type":"text"},"source":["Can quickly you code step 1 above with the fit and transform paradigm in sklearn, instead of fit?"]},{"cell_type":"markdown","metadata":{"id":"Xqb7L9Sd3UAI","colab_type":"text"},"source":["#### <font color='green'>Solution 1"]},{"cell_type":"code","metadata":{"id":"1yJc06_g4OQJ","colab_type":"code","colab":{}},"source":["# INSERT YOUR CODE HERE"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kOjMTLpcgVWM","colab_type":"text"},"source":["# <font color='blue'>D. Define a NN model"]},{"cell_type":"markdown","metadata":{"id":"aojQqRbG66r1","colab_type":"text"},"source":["## D1. Baseline NN model"]},{"cell_type":"markdown","metadata":{"id":"wniR0Ga4gVWN","colab_type":"text"},"source":["You can create a baseline NN - a simple **Fully Connected NN (FCNN)** - for the IRIS multiclass classification problem with just one function:\n","   * input\n","       * as per our input dataset, this NN has 4 inputs (X)\n","   * hidden layer(s)\n","       * the hidden layer here has 8 nodes, and uses a rectifier (**relu**) activation function, which is a good practice\n","   * output\n","       * because we used a one-hot encoding for the dataset, the output layer must create 3 output values, one for each class. We use a **softmax** activation function in the output layer, to ensure the output values are in the range of 0 and 1 and may be used as predicted probabilities: the output value with the largest value will be taken as the class predicted by the model. Finally, the network uses the efficient **adam** GD optimization algorithm with a **logarithmic loss function**, which is called **categorical crossentropy** in Keras.   \n","   \n","Hence, the network topology of this simple 1-layer FCNN can be summarized as:\n","\n","    4 inputs -> 1 hidden layer with 8 nodes -> 3 outputs\n","\n","and it simplementation in Keras is as simple as follows:"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"hW_G8_RYgVWN","colab_type":"code","colab":{}},"source":["# create model\n","model = Sequential()\n","model.add(Dense(8, input_dim=4, activation='relu'))\n","model.add(Dense(3, activation='softmax'))\n","\n","# Compile model\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mxpvOYV0DfSF","colab_type":"code","colab":{}},"source":["model.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fbf74Lb3C55F","colab_type":"code","colab":{}},"source":["%%time\n","#0 history=model.fit(X, Y, epochs=10)           # <-- error!\n","#1 \n","history=model.fit(X, transformed_Y, epochs=10)\n","#2 history=model.fit(X, transformed_Y, epochs=50)\n","#3 history=model.fit(X, transformed_Y, epochs=100)\n","#4 -- more refined? add e.g. batch_size=32, or 10"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DpMABnAlgVWX","colab_type":"code","colab":{}},"source":["my_variable=history.history[\"accuracy\"]\n","plt.plot(range(len(my_variable)),my_variable)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YSj9kLXogVWZ","colab_type":"text"},"source":["## D2. Train-Test splitting"]},{"cell_type":"code","metadata":{"id":"venhGK2egVWa","colab_type":"code","colab":{}},"source":["X_train, X_test, Y_train, Y_test = train_test_split(X, transformed_Y, test_size=0.2, random_state=seed)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hlIhxsXkgVWj","colab_type":"code","colab":{}},"source":["# create model\n","model = Sequential()\n","model.add(Dense(8, input_dim=4, activation='relu'))\n","model.add(Dense(3, activation='softmax'))\n","# Compile model\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Yq8rFoargVWv","colab_type":"code","colab":{}},"source":["model.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"T2W6Jqda7UTM","colab_type":"code","colab":{}},"source":["%%time\n","#1 \n","history=model.fit(X_train, Y_train, epochs=10, validation_data=(X_test,Y_test))\n","#2 history=model.fit(X_train, Y_train, epochs=100, validation_data=(X_test,Y_test))\n","#3 history=model.fit(X_train, Y_train, epochs=500, validation_data=(X_test,Y_test))  <-- signs of overfitting!\n","#4 history=model.fit(X_train, Y_train, epochs=120, validation_data=(X_test,Y_test), batch_size=32)\n","#5 history=model.fit(X_train, Y_train, epochs=100, validation_data=(X_test,Y_test), batch_size=10)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"w4-JaauPgVWm","colab_type":"code","colab":{}},"source":["variable1=history.history[\"loss\"]\n","variable2=history.history[\"val_loss\"]\n","plt.plot(range(len(variable1)),variable1, label='loss')\n","plt.plot(range(len(variable2)),variable2, label='val_loss')\n","plt.legend()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_rUgHNR19ndY","colab_type":"text"},"source":["## D3. Introduce KerasClassifier"]},{"cell_type":"markdown","metadata":{"id":"USfXi8lXgVW4","colab_type":"text"},"source":["\n","\n","The idea here is to use the Keras library which provides wrapper classes to allow you to use NN models developed with Keras in scikit-learn. Why so? Because you get the best from both: Keras is simple and useful for NN design, and scikit-learn is powerful and versatile for many ML-related tasks.\n","\n","There is a *KerasClassifier* class in Keras that can be used as an *Estimator* in scikit-learn, the base type of model in the library. We need to actually create our KerasClassifier first, to be used in scikit-learn. KerasClassifier takes the name of a function (the one we wrote above) as an argument, plus arguments that will be passed on to the *fit()* function internally used to train the NN. Here, we pass:\n","\n","* a number of epochs as 200\n","* a batch size as 5 \n","\n","to use when training the model. Debugging is also turned off when training by setting verbose to 0.\n","    \n","This function returns the constructed NN model, ready for training.\n","\n","More info: https://keras.io/scikit-learn-api/"]},{"cell_type":"code","metadata":{"id":"woNQrIligVW5","colab_type":"code","colab":{}},"source":["# define a baseline model\n","def baseline_model():\n","    # create model\n","    model = Sequential()\n","    model.add(Dense(8, input_dim=4, activation='relu'))\n","    model.add(Dense(3, activation='softmax'))\n","    # Compile model\n","    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cOKwv9eggVXG","colab_type":"code","colab":{}},"source":["estimator = KerasClassifier(build_fn=baseline_model, epochs=200, batch_size=5, verbose=0)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ypDEQp_4gVX_","colab_type":"code","colab":{}},"source":["estimator"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"B4S8oaIfAvTD","colab_type":"text"},"source":["## D4. Evaluate the model with $k$-Fold Cross-Validation"]},{"cell_type":"markdown","metadata":{"id":"ERcfNKaJgVYG","colab_type":"text"},"source":["It is time to evaluate our NN model on our training data, a.k.a. the \"training\" phase.\n","\n","The scikit-learn library has excellent capability to evaluate models using a suite of techniques. The gold standard for evaluating ML models is **k-fold cross-validation (k-fold CV)**. We do as follows:\n","\n","1. we define the model evaluation procedure.\n","      * here, we shuffle the data before partitioning it, and we set the number of folds to 10 (a good default)\n","     \n","     \n","2. we evaluate our model (*estimator*) on our dataset (*X* and *transformed_Y*) using a 10-fold CV procedure (k-fold)\n","\n","Evaluating the model only takes approximately 10 seconds and returns an object that describes the evaluation of the k=10 constructed models for each of the splits of the dataset. \n","\n","The results are summarized as both the mean and standard deviation of the model accuracy on the dataset."]},{"cell_type":"code","metadata":{"id":"3faFyYVTgVYG","colab_type":"code","colab":{}},"source":["# part 1\n","kfold = KFold(n_splits=10, shuffle=True, random_state=seed)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"75t-WSqCgVYM","colab_type":"code","colab":{}},"source":["%%time\n","# part 2\n","results = cross_val_score(estimator, X, transformed_Y, cv=kfold)\n","print(\"Accuracy: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RYB4F0qg-mfG","colab_type":"text"},"source":["Note that the step above is taking quite some more time than other previous cells.."]},{"cell_type":"markdown","metadata":{"id":"c7MqNnPzgVYf","colab_type":"text"},"source":["What we got is a reasonable estimation of the performance of the model on unseen data. It is also within the realm of known top results for this problem."]}]}