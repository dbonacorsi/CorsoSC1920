{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 2","language":"python","name":"python2"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.16"},"colab":{"name":"Project_IRIS1_Sklearn.ipynb","provenance":[{"file_id":"https://github.com/bonacor/CorsoSwComp/blob/master/Project_IRIS1_Sklearn.ipynb","timestamp":1589297385085}],"collapsed_sections":["9IqCR8K5gTwn","sUHJjeC3gTwo","Gi8yI0oOgTxQ","KAAUwsXkgTxV","kpaV2MSCooFj","9n782sk0gTxc","Z6OOwWtmpM6w","pz9bSGLZ2j_s","ini0n7Rp2ol-","jsUAmyWF2XQk","jP3kWj0x2yoZ","jYKGUGW95OQ0","7p503m4E5N-e","7HlDFWgVnnMJ","oh2pqQ2BnxDd"]}},"cells":[{"cell_type":"markdown","metadata":{"id":"Eba7lM88gTwl","colab_type":"text"},"source":["# Project IRIS - Phase 1: sklearn</font>\n"]},{"cell_type":"markdown","metadata":{"id":"XltJuX_OgTwm","colab_type":"text"},"source":["In this tutorial you will discover **how to use sklearn to run a decision tree classifier in machine learning**. \n","\n","Goals:\n","* How to load data from CSV and make it available to you\n","* Go straight to create a model and run a classification"]},{"cell_type":"markdown","metadata":{"id":"9IqCR8K5gTwn","colab_type":"text"},"source":["# <font color='blue'>A. Description of the input data"]},{"cell_type":"code","metadata":{"id":"bIsKU5VvwIIC","colab_type":"code","colab":{}},"source":["!wget http://bonacor.web.cern.ch/bonacor/SC_AA1920/images/iris.png\n","from IPython.display import Image\n","Image(filename='/content/iris.png')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1ROh35TwgTwo","colab_type":"text"},"source":["The iris flowers dataset is a standard ML dataset, widely used worldwide as benchmark.\n","\n","### Dataset availability:\n","\n","Almost ubiquitous.. e.g.\n","   * [UCI Machine Learning Repository page](https://archive.ics.uci.edu/ml/datasets/Iris)\n","\n","More easily, get it from the github of these hands-on, at this direct URL:\n","   * [https://raw.githubusercontent.com/dbonacorsi/SC_AA1920/master/datasets/iris.data.csv](https://raw.githubusercontent.com/dbonacorsi/SC_AA1920/master/datasets/iris.data.csv)\n","\n","### Dataset description:\n","\n","* This is a good example to practice on a multiclass classification problem.\n","* Each instance describes the properties of an observed iris flower measurements\n","* All of the 4 input variables are numeric and have the same scale (cm)\n","   * Sepal length in centimeters \n","   * Sepal width in centimeters \n","   * Petal length in centimeters \n","   * Petal width in centimeters\n","* The output variable is a specific iris species (3 possibilities)\n","   * the \"class\", e.g. \"Iris-setosa\", \"Iris-versicolor\" or \"Iris-verginica\"\n","\n","### How the dataset looks like:\n","\n","\n","    5.1,3.5,1.4,0.2,Iris-setosa\n","    4.9,3.0,1.4,0.2,Iris-setosa\n","    4.7,3.2,1.3,0.2,Iris-setosa\n","    4.6,3.1,1.5,0.2,Iris-setosa\n","    5.0,3.6,1.4,0.2,Iris-setosa\n","    (...)\n","\n","\n","### Additional input from best practitioners:\n","\n","The iris flower dataset is a well studied problem and as such we can expect to achieve a model accuracy in the range of 95% to 97%. Use this as target to aim for when developing your model(s)."]},{"cell_type":"markdown","metadata":{"id":"sUHJjeC3gTwo","colab_type":"text"},"source":["# <font color='blue'>B. Data import (+ quick data exploration) + data preparation"]},{"cell_type":"markdown","metadata":{"id":"2U8nPURTgTwp","colab_type":"text"},"source":["Start by importing all classes and functions you will need:\n","* data loading functionalities from **Pandas** (learn more [here](https://pandas.pydata.org/))\n","* data preparation and model evaluation from **Scikit-learn** - referred to as `sklearn` in the following (learn more [here](https://scikit-learn.org/stable/))"]},{"cell_type":"code","metadata":{"id":"_thn6_CzgTwq","colab_type":"code","colab":{}},"source":["# pandas\n","from pandas import read_csv\n","\n","# sklearn\n","# ... later ..."],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"y2umF3iMARPt","colab_type":"text"},"source":["Download and import the data. You can do it in various ways. "]},{"cell_type":"code","metadata":{"id":"uJRjLkeOgTww","colab_type":"code","colab":{}},"source":["# you can directly download the data and inspect it\n","\n","# --- download\n","#!wget https://raw.githubusercontent.com/dbonacorsi/SC_AA1920/master/datasets/iris.data.csv\n","#!ls -trl iris.data.csv\n","#!head -5 iris.data.csv\n","# --- import\n","#dataframe = read_csv(\"iris.data.csv\", header=None)\n","#dataset = dataframe.values\n","\n","# but we do something slightly more sophisticated - see below."],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4DE0y6Io-viI","colab_type":"text"},"source":["The output variable contains strings, so it is suggested (easiest) to load the data using **pandas** into a DataFrame."]},{"cell_type":"code","metadata":{"id":"Dr6Pwtdz7zlx","colab_type":"code","colab":{}},"source":["import pandas as pd\n","\n","url = 'https://raw.githubusercontent.com/dbonacorsi/SC_AA1920/master/datasets/iris.data.csv'\n","\n","names = ['sepal-l', 'sepal-w', 'petal-l', 'petal-w', 'class']\n","dataset = pd.read_csv(url, names=names)\n","dataset"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wi6SA3DP69SK","colab_type":"code","colab":{}},"source":["shape = dataset.shape\n","shape"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"09HCyx8q69Ow","colab_type":"code","colab":{}},"source":["class_counts = dataset.groupby('class').size()\n","print(class_counts)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1OBCqxHj69Ly","colab_type":"code","colab":{}},"source":["from pandas import set_option\n","\n","set_option('display.width', 200)\n","set_option('display.max_rows', 500)\n","set_option('display.max_columns', 500)\n","set_option('precision', 3)        \n","\n","description = dataset.describe()\n","print(description)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"K3Y0TYo3868K","colab_type":"code","colab":{}},"source":["from matplotlib import pyplot\n","\n","dataset.hist()\n","pyplot.rcParams[\"figure.figsize\"] = [8,8]\n","pyplot.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K-d2Y2IF-aTw","colab_type":"text"},"source":["Now, split the attributes (i.e. columns) into input variables (the matrix of **features X**) and output variables (the vector **label Y**)."]},{"cell_type":"code","metadata":{"id":"94OLyiJB679U","colab_type":"code","colab":{}},"source":["data = dataset.values\n","data"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OeYM1VQy_yE1","colab_type":"code","colab":{}},"source":["X = data[:,0:4].astype(float)   # columns from 1st to 4th into X\n","Y = data[:,4]                   # column 5th into Y"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"U8yY6yFMgTw-","colab_type":"code","colab":{}},"source":["len(X)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uC3lGbsSgTxE","colab_type":"code","colab":{}},"source":["len(Y)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4T4kTgzqgTxI","colab_type":"code","colab":{}},"source":["X"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LDsaGcF3gTxL","colab_type":"code","colab":{}},"source":["Y"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Gi8yI0oOgTxQ","colab_type":"text"},"source":["# <font color='blue'>C. Model creation, training and inference"]},{"cell_type":"markdown","metadata":{"id":"BQvJnXaylPvK","colab_type":"text"},"source":["In a real ML project, you will spent **plenty** of time before getting to this point, in **data exploration** as well as **data preparation**, keys towards success. Nevertheless, in this example, data is relatively easy, and already clean and ready to use, so you can go straight to creating a ML model."]},{"cell_type":"code","metadata":{"id":"MjfrV9RVgTxQ","colab_type":"code","colab":{}},"source":["#iris = load_iris()\n","#X = iris.data[:, 2:] # petal length and width\n","#y = iris.target\n","\n","from sklearn.tree import DecisionTreeClassifier\n","\n","tree_clf = DecisionTreeClassifier(max_depth=2)\n","tree_clf.fit(X, Y)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CJgn6TCPlmQ2","colab_type":"text"},"source":["Learn more in the sklearn official documentation for [DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)"]},{"cell_type":"markdown","metadata":{"id":"2-Vnob50mYgW","colab_type":"text"},"source":["Note that we used the fit paradigm of sklearn, and not the fit_transform one. Discussion in the virtual lab."]},{"cell_type":"markdown","metadata":{"id":"KAAUwsXkgTxV","colab_type":"text"},"source":["# <font color='red'>Exercise 1: Run model prediction (difficulty: easy)"]},{"cell_type":"markdown","metadata":{"id":"391JTHZhgTxW","colab_type":"text"},"source":["Explore the sklearn documentation to find a way to:\n","   * extract the probability classes of the following observation: 6.3, 2.5, 4.9, 1.5\n","   * extract the predicted class "]},{"cell_type":"markdown","metadata":{"id":"kpaV2MSCooFj","colab_type":"text"},"source":["## <font color='green'> Solution 1"]},{"cell_type":"code","metadata":{"id":"mZ9Djc4rgTxY","colab_type":"code","colab":{}},"source":["## INSERT YOUR CODE HERE"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9n782sk0gTxc","colab_type":"text"},"source":["# <font color='red'>Exercise 2: Repeat with less features (difficulty: moderate)"]},{"cell_type":"markdown","metadata":{"id":"AuX4Nub6gTxd","colab_type":"text"},"source":["1.   Modify this notebook to run Exercise 1 by having a dataset in input that only has **sepal-l** and **sepal-w** (i.e. the first 2 features in the columns you have been given), instead of the full 4 features available. Then, redo the modelling and prediction. Do you see any change? Why?\n","2.   Same as above, by using only the last 2 features instead (**petal-l** and **petal-w**). Do you see any change? Why? \n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Z6OOwWtmpM6w","colab_type":"text"},"source":["## <font color='green'>Solution 2"]},{"cell_type":"code","metadata":{"id":"O-88LaCE3gg8","colab_type":"code","colab":{}},"source":["## INSERT YOUR CODE HERE"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pz9bSGLZ2j_s","colab_type":"text"},"source":["# <font color='red'>Exercise 3: Import data differently (difficulty: easy)"]},{"cell_type":"markdown","metadata":{"id":"rQvW6uFB20xR","colab_type":"text"},"source":["The iris dataset is so famous, and sklearn so widespread, that you can import the iris dataset directly from sklearn. Just try the following and compare with what we did before.\n","```\n","from  sklearn import  datasets\n","iris=datasets.load_iris()\n","\n","X=iris.data\n","Y=iris.target\n","```\n"]},{"cell_type":"markdown","metadata":{"id":"ini0n7Rp2ol-","colab_type":"text"},"source":["## <font color='green'>Solution 3"]},{"cell_type":"code","metadata":{"id":"rU9OdF_X5yDf","colab_type":"code","colab":{}},"source":["## INSERT YOUR CODE HERE"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jsUAmyWF2XQk","colab_type":"text"},"source":["# <font color='red'>Exercise 4: Perform train/test splitting (difficulty: moderate)"]},{"cell_type":"markdown","metadata":{"id":"jP3kWj0x2yoZ","colab_type":"text"},"source":["## <font color='green'>Solution 4"]},{"cell_type":"code","metadata":{"id":"ap_QyTNs5zjM","colab_type":"code","colab":{}},"source":["## INSERT YOUR CODE HERE"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jYKGUGW95OQ0","colab_type":"text"},"source":["# <font color='red'>Exercise 5: Try a different model"]},{"cell_type":"markdown","metadata":{"id":"P67n3r2H5OIs","colab_type":"text"},"source":["Is a Decision Tree the best choice? Try a different model, e.g. a KNeighborsClassifier - find in sklearn documentation how to use it!"]},{"cell_type":"markdown","metadata":{"id":"7p503m4E5N-e","colab_type":"text"},"source":["## <font color='green'>Solution 5"]},{"cell_type":"code","metadata":{"id":"DiLoZJ0J5ZD2","colab_type":"code","colab":{}},"source":["## INSERT YOUR CODE HERE"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7HlDFWgVnnMJ","colab_type":"text"},"source":["# <font color='red'>Exercise 6: Hyperparameter tuning (difficulty: moderate to high)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"oh2pqQ2BnxDd","colab_type":"text"},"source":["## <font color='green'>Solution 6"]},{"cell_type":"code","metadata":{"id":"mPtUU7qGn5A1","colab_type":"code","colab":{}},"source":["## INSERT YOUR CODE HERE"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"T10QwZGbnw6C","colab_type":"code","colab":{}},"source":["from sklearn.model_selection import GridSearchCV\n","clf = tree.DecisionTreeClassifier(random_state=123)\n","grid_values = {'max_depth': [2,5,10,20,30],'min_samples_split':[2,3,4,5], 'min_samples_leaf':[2,3,4,5]}\n","grid = GridSearchCV(clf, param_grid = grid_values,scoring = 'accuracy')\n","grid_result = grid.fit(X, Y)\n","\n","# summarize results\n","print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n","means = grid_result.cv_results_['mean_test_score']\n","stds = grid_result.cv_results_['std_test_score']\n","params = grid_result.cv_results_['params']\n","for mean, stdev, param in zip(means, stds, params):\n","    print(\"%f (%f) with: %r\" % (mean, stdev, param))"],"execution_count":0,"outputs":[]}]}